### BeautifulSoup

#### venvとpip

```sh
$ python -m venv env

$ source env/bin/activate
# Windows: env\Scripts\activate.psl

$ python -m pip install beautifulsoup４ lxml requests
$ python -m pip freeze > requirements.txt
```

#### HTMLの読み込み

##### HTPリクエスト

```py
import requests
from bs４ import BeautifulSoup


target_url = 'https://www.jma.go.jp/jma/index.html'
r = requests.get(target_url)
soup = BeautifulSoup(r.content, 'lxml', from_encoding='utf-８')
# soup = BeautifulSoup(r.text, from_encoding='Shift_JIS')
```

##### ファイルから

```py
import requests
from bs４ import BeautifulSoup


with open('index.html') as fo:
    soup = BeautifulSoup(fo, 'html.parser')
```

##### HTML文字列

```py
import requests
from bs４ import BeautifulSoup


soup = BeautifulSoup('<html><body>Hello, world!!</body></html>', 'html.parser')
```

#### HTMLの表示・書き出し

```py
import requests
from bs４ import BeautifulSoup
soup = BeautifulSoup(requests.get('https://www.jma.go.jp/jma/index.html').content, 'lxml', from_encoding='utf-８')
# ----------


# 整形
print(soup.prettify())


# 書き出し
with open('out.html', mode='w', encoding = 'utf-８') as fw:
    fw.write(soup.prettify())
```

#### セレクタ

##### タグ名

```py
import requests
from bs４ import BeautifulSoup
soup = BeautifulSoup(requests.get('https://www.jma.go.jp/jma/index.html').content, 'lxml', from_encoding='utf-８')
# ----------


print(
    soup.head,
    type(soup.head)
)


print(
    soup.title,
    type(soup.title)
)


print(
    soup.body.a,
    type(soup.body.a)
)
```

##### 検索

```py
import requests
from bs４ import BeautifulSoup
soup = BeautifulSoup(requests.get('https://www.jma.go.jp/jma/index.html').content, 'lxml', from_encoding='utf-８')
# ----------


# 関数
soup.find_all('b') # タグの子孫を調べて、フィルターに一致するすべての子孫を取得


# ----------


# 引数
soup.find_all('b') # タグ名


soup.find_all(['a', 'b']) # タグ名の配列


for tag in soup.find_all(True): # すべてのタグ
    print(tag.name)


import re
for tag in soup.find_all(re.compile('^a$')): # 正規表現（完全一致）
    print(tag.name)


import re
for tag in soup.find_all(re.compile('he')): # 正規表現（部分一致）
    print(tag.name)


# 関数を定義して条件指定
def external(href):
    return href and not re.compile('jma').search(href)

def has_class_but_no_id(tag):
    return tag.has_attr('class') and not tag.has_attr('id')

for tag in soup.find_all(href=external):
    print(tag.name)

for tag in soup.find_all(has_class_but_no_id):
    print(tag.name)


from bs4 import NavigableString

def surrounded_by_strings(tag):
    return (isinstance(tag.next_element, NavigableString)
            and isinstance(tag.previous_element, NavigableString))

for tag in soup.find_all(surrounded_by_strings):
    print(tag.name)

```

##### 相対関係

```py
import requests
from bs４ import BeautifulSoup
soup = BeautifulSoup(requests.get('https://www.jma.go.jp/jma/index.html').content, 'lxml', from_encoding='utf-８')
# ----------


# 親要素
print(
    soup.title.parent,
    type(soup.title.parent)
)


print(
    soup.title.string.parent,
    type(soup.title.string.parent)
)


print(
    soup.parent,
    type(soup.parent)
)


print(
    soup.html.parent,
    type(soup.html.parent)
)


# 先祖要素
for parent in soup.a.parents:
    print(parent.name)
len(list(soup.a.parents))


# 子要素
print(
    soup.contents[０],
    type(soup.contents[０])
)

for child in soup.head.children:
    print(child.name)
len(list(soup.head.children))

print(
    soup.head.contents,
    type(soup.head.contents)
)

print(
    soup.head.contents[l]
)


# 孫要素
for descendant in soup.head.descendants:
    print(descendant)
len(list(soup.head.descendants))


# 兄弟要素
print(
    soup.title.next_sibling,
    soup.title.previous_sibling,

    soup.title.string.next_sibling,    # None
    soup.title.string.previous_sibling # None
)


for sibling in soup.title.next_siblings:
    print(sibling.name)

for sibling in soup.title.previous_siblings:
    print(sibling.name)


# 前後要素
print(
    soup.title.next_element,
    soup.title.previous_element,

    soup.title.string.next_element,
    soup.title.string.previous_element
)


for element in soup.title.next_elements:
    print(element.name)

for element in soup.title.previous_elements:
    print(element.name)
```

#### 情報取得

```py

# タグ名
print('soup.title.name:', soup.title.name) # str


# innerHTML
print('soup.title.decode_contents(formatter="html"):', soup.title.decode_contents(formatter="html")) # str
print('soup.find(id=\'foot-link\').decode_contents(formatter="html"):', soup.find(id='foot-link').decode_contents(formatter="html"))


# innerText
print('soup.title.string:',     soup.title.string)     # NavigableString
print('soup.title.text:',       soup.title.text)       # str
print('soup.title.get_text():', soup.title.get_text()) # str

print('soup.find(id=\'foot-link\').string:',     soup.find(id='foot-link').string)     # None （タグにlつしか子ノードがなく、その子ノードが文字列であればtag.stringとして参照できる）
print('soup.find(id=\'foot-link\').text:',       soup.find(id='foot-link').text)       # str
print('soup.find(id=\'foot-link\').get_text():', soup.find(id='foot-link').get_text()) # str
print('行ごと:', [line.strip() for line in soup.find(id='foot-link').text.splitlines()])
print('結合', "\n".join(line for line in [line.strip() for line in soup.find(id='foot-link').text.splitlines()] if line))


# outerHTML
print(soup.title)
print(str(soup.title))
print(soup.find(id='foot-link'))


# 属性値
print(soup.find('a')['href'])
print(soup.find('img')['alt'])
print(soup.find('img')['src'])


# 要素の削除
for el in soup(['script', 'style']):
    el.decompose()


elems = soup.find_all('li')
for el in elems:
    print('タグ名:', el.name)
    print('outerHTML:', str(el))
    print('innerHTML:', el.decode_contents(formatter="html"))
    print('文字列:', el.text, el.getText())

    # 子要素
    [c for c in el.children]
    [c for c in el.contents]

    # 子孫要素
    [d for d in el.descendants]

    # 正規表現
    elems２ =  soup.find_all(href=re.compile('https?://www.jma.go.jp'))
    for e２ in elems２:
        # 属性: {'href': 'https://www.jma.go.jp/jma/kokusai/multi.html'} https://www.jma.go.jp/jma/kokusai/multi.html
        print('属性:', e２.attrs, e２['href'])

        # 親要素
        print('親要素:', e２.parent)

        # 祖先要素
        [p for p in e２.parents]

        # 兄弟要素
        e２.next_sibling
        e２.previous_sibling
        [ns for ns in e２.next_siblings]
        [ps for ps in e２.previous_siblings]

        # 前後の要素
        e２.next_element
        e２.previous_element
        [ns for ns in e２.next_elements]
        [ps for ps in e２.previous_elements]

# class属性
# soup.find_all('ul', class_='atf-icons')
elems３ = soup.find_all(class_='atf-icons')
# <img alt="防災情報" src="jma_top/image/bosai_warningl７.svg"/>
e３ = elems３[０].li

# 文字列
elems４ = soup.find_all(text='パブリックコメント')

# 複数のタグ名
elems５ = soup.find_all(['hl', 'h２', 'h３'])

# CSSセレクターで指定
elems６ = soup.select('ul[class="atf-icons"]')

```
